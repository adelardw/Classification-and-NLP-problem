{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212},{"sourceId":2345761,"sourceType":"datasetVersion","datasetId":1416132},{"sourceId":2936819,"sourceType":"datasetVersion","datasetId":1800581}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/seq2seq-f256f7cc-0e31-41eb-b554-8150c37bf037.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240806/auto/storage/goog4_request&X-Goog-Date=20240806T123900Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=3f6ec6c27384e87bff2d3c33e53eb638b6dd7e37079f835378ef5c635a8172c410d20bdf212dd5f9a4e957845317a03bc20ab26c9e5c70d7cd50c88804ce1133299e4b40fbe7eb3e9889d31cebc25c155e21dfef95d1eb46db901f30ec0adca4d94cd7e56e5a2e7e619212e148f7be8842bacbe167b2ffcf2c60c3e1235d0cabf744132426386a5f73bff9a31c5010dc53beffa9e3ecd1005b8975aca69b6a4244f1137fd8374904b5472acb28c381590e71fad442bd7a9718fb7ef8b3ae99fd693e9eb4e94ace544b7bdb10bc83ff43a0158875da82241b63685170915aae699ac2af3530606b020ccf6719355d4b49155751586c29623a40f2c4a5b62c0d0a","timestamp":1722955542958}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python3 -m spacy download de_core_news_sm\n!pip install pandarallel\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"id":"3jIQT8iPszbx","executionInfo":{"status":"ok","timestamp":1722948048057,"user_tz":-180,"elapsed":23180,"user":{"displayName":"","userId":""}},"outputId":"e3333cb1-d08c-4ee3-8e2e-72719c7e68c2","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-08-06T14:47:10.072418Z","iopub.execute_input":"2024-08-06T14:47:10.073131Z","iopub.status.idle":"2024-08-06T14:47:49.902775Z","shell.execute_reply.started":"2024-08-06T14:47:10.073100Z","shell.execute_reply":"2024-08-06T14:47:49.901644Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.7.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\nInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\nCollecting pandarallel\n  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: dill>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (0.3.8)\nRequirement already satisfied: pandas>=1 in /opt/conda/lib/python3.10/site-packages (from pandarallel) (2.2.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from pandarallel) (5.9.3)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1->pandarallel) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\nBuilding wheels for collected packages: pandarallel\n  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16672 sha256=bc7e687cc0b356058ba8ce22e14045cb1ea43324726e3ac58fea294c8e40ef38\n  Stored in directory: /root/.cache/pip/wheels/50/4f/1e/34e057bb868842209f1623f195b74fd7eda229308a7352d47f\nSuccessfully built pandarallel\nInstalling collected packages: pandarallel\nSuccessfully installed pandarallel-1.6.5\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/machine-translation-dataset-de-en/translation_train.csv')\ndataset_test = pd.read_csv('/kaggle/input/machine-translation-dataset-de-en/translation_test.csv')\ndataset = dataset[dataset.columns[::-1]]\ndataset","metadata":{"id":"4CMFOkReszbx","executionInfo":{"status":"ok","timestamp":1722948051237,"user_tz":-180,"elapsed":396,"user":{"displayName":"","userId":""}},"outputId":"40de57aa-b7b6-4b05-a792-745f7ab22c46","colab":{"base_uri":"https://localhost:8080/","height":424},"execution":{"iopub.status.busy":"2024-08-06T14:48:15.721263Z","iopub.execute_input":"2024-08-06T14:48:15.721638Z","iopub.status.idle":"2024-08-06T14:48:15.827830Z","shell.execute_reply.started":"2024-08-06T14:48:15.721609Z","shell.execute_reply":"2024-08-06T14:48:15.826651Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  german  \\\n0      Zwei junge weiße Männer sind im Freien in der ...   \n1      Mehrere Männer mit Schutzhelmen bedienen ein A...   \n2      Ein kleines Mädchen klettert in ein Spielhaus ...   \n3      Ein Mann in einem blauen Hemd steht auf einer ...   \n4      Zwei Männer stehen am Herd und bereiten Essen zu.   \n...                                                  ...   \n28995  Eine Frau schreibt hinter einer verschnörkelte...   \n28996          Ein Bergsteiger übt an einer Kletterwand.   \n28997  Zwei Bauarbeiter arbeiten auf einer Straße vor...   \n28998  Ein älterer Mann sitzt mit einem Jungen mit ei...   \n28999  Ein Mann in Shorts und Hawaiihemd lehnt sich ü...   \n\n                                                 english  \n0      Two young, White males are outside near many b...  \n1      Several men in hard hats are operating a giant...  \n2        A little girl climbing into a wooden playhouse.  \n3      A man in a blue shirt is standing on a ladder ...  \n4               Two men are at the stove preparing food.  \n...                                                  ...  \n28995          A woman behind a scrolled wall is writing  \n28996  A rock climber practices on a rock climbing wall.  \n28997  Two male construction workers are working on a...  \n28998  An elderly man sits outside a storefront accom...  \n28999  A man in shorts and a Hawaiian shirt leans ove...  \n\n[29000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>german</th>\n      <th>english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n      <td>Two young, White males are outside near many b...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n      <td>Several men in hard hats are operating a giant...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n      <td>A little girl climbing into a wooden playhouse.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ein Mann in einem blauen Hemd steht auf einer ...</td>\n      <td>A man in a blue shirt is standing on a ladder ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n      <td>Two men are at the stove preparing food.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28995</th>\n      <td>Eine Frau schreibt hinter einer verschnörkelte...</td>\n      <td>A woman behind a scrolled wall is writing</td>\n    </tr>\n    <tr>\n      <th>28996</th>\n      <td>Ein Bergsteiger übt an einer Kletterwand.</td>\n      <td>A rock climber practices on a rock climbing wall.</td>\n    </tr>\n    <tr>\n      <th>28997</th>\n      <td>Zwei Bauarbeiter arbeiten auf einer Straße vor...</td>\n      <td>Two male construction workers are working on a...</td>\n    </tr>\n    <tr>\n      <th>28998</th>\n      <td>Ein älterer Mann sitzt mit einem Jungen mit ei...</td>\n      <td>An elderly man sits outside a storefront accom...</td>\n    </tr>\n    <tr>\n      <th>28999</th>\n      <td>Ein Mann in Shorts und Hawaiihemd lehnt sich ü...</td>\n      <td>A man in shorts and a Hawaiian shirt leans ove...</td>\n    </tr>\n  </tbody>\n</table>\n<p>29000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import spacy\nimport nltk\n\ndef preprocessing(data,\n                  preprocess_column = 'En',\n                  n_workers = 32,\n                  lang_stopwords = None,\n                  corpus = None,\n                  lower = False):\n\n    import pandarallel\n    from pandarallel import pandarallel\n    import re\n\n\n    pandarallel.initialize(progress_bar=False, nb_workers=n_workers)\n\n    data = data.copy()\n    data[preprocess_column] = data[preprocess_column]\n\n    pandarallel.initialize(nb_workers=n_workers)\n\n\n    if lower:\n        data[preprocess_column] = data[preprocess_column].\\\n                                         parallel_apply(lambda text: text.lower())\n\n    if corpus is not None:\n        nlp = spacy.load(corpus)\n        data[preprocess_column] = data[preprocess_column].\\\n                                         parallel_apply(lambda text: \" \".join([token.text for token in nlp.tokenizer(text)]))\n    if lang_stopwords is not None:\n        sw = nltk.corpus.stopwords.words(lang_stopwords)\n        data[preprocess_column] = data[preprocess_column].\\\n                                         parallel_apply(lambda text: \" \".join([word for word in text.split() if word not in sw]))\n\n    return data\n\n\nen_corpus = 'en_core_web_sm'\nde_corpus = 'de_core_news_sm'\n\npreprocessed_df = preprocessing(dataset,\n                                preprocess_column = 'english',\n                                corpus = en_corpus,\n                                lower=True,\n                                n_workers = 16)\n\npreprocessed_df = preprocessing(preprocessed_df,\n                                preprocess_column = 'german',\n                                corpus = de_corpus,\n                                lower=True,\n                                n_workers = 16)","metadata":{"id":"NdkdUu9wszby","executionInfo":{"status":"ok","timestamp":1722948141750,"user_tz":-180,"elapsed":86866,"user":{"displayName":"","userId":""}},"outputId":"64035ab6-33ca-46c0-86a8-1f0de2cbbc49","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-08-06T14:48:18.449361Z","iopub.execute_input":"2024-08-06T14:48:18.449763Z","iopub.status.idle":"2024-08-06T14:49:00.728916Z","shell.execute_reply.started":"2024-08-06T14:48:18.449733Z","shell.execute_reply":"2024-08-06T14:49:00.727860Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"INFO: Pandarallel will run on 16 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\nINFO: Pandarallel will run on 16 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\nINFO: Pandarallel will run on 16 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\nINFO: Pandarallel will run on 16 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocessed_df","metadata":{"id":"cL-HuK0Oszbz","executionInfo":{"status":"ok","timestamp":1722948148366,"user_tz":-180,"elapsed":395,"user":{"displayName":"","userId":""}},"outputId":"1e1f1a16-e19d-489b-c151-c59d3da8547c","colab":{"base_uri":"https://localhost:8080/","height":424},"execution":{"iopub.status.busy":"2024-08-06T14:49:05.720308Z","iopub.execute_input":"2024-08-06T14:49:05.721475Z","iopub.status.idle":"2024-08-06T14:49:05.734814Z","shell.execute_reply.started":"2024-08-06T14:49:05.721441Z","shell.execute_reply":"2024-08-06T14:49:05.733572Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  german  \\\n0      zwei junge weiße männer sind im freien in der ...   \n1      mehrere männer mit schutzhelmen bedienen ein a...   \n2      ein kleines mädchen klettert in ein spielhaus ...   \n3      ein mann in einem blauen hemd steht auf einer ...   \n4      zwei männer stehen am herd und bereiten essen ...   \n...                                                  ...   \n28995  eine frau schreibt hinter einer verschnörkelte...   \n28996         ein bergsteiger übt an einer kletterwand .   \n28997  zwei bauarbeiter arbeiten auf einer straße vor...   \n28998  ein älterer mann sitzt mit einem jungen mit ei...   \n28999  ein mann in shorts und hawaiihemd lehnt sich ü...   \n\n                                                 english  \n0      two young , white males are outside near many ...  \n1      several men in hard hats are operating a giant...  \n2       a little girl climbing into a wooden playhouse .  \n3      a man in a blue shirt is standing on a ladder ...  \n4              two men are at the stove preparing food .  \n...                                                  ...  \n28995          a woman behind a scrolled wall is writing  \n28996  a rock climber practices on a rock climbing wa...  \n28997  two male construction workers are working on a...  \n28998  an elderly man sits outside a storefront accom...  \n28999  a man in shorts and a hawaiian shirt leans ove...  \n\n[29000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>german</th>\n      <th>english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zwei junge weiße männer sind im freien in der ...</td>\n      <td>two young , white males are outside near many ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mehrere männer mit schutzhelmen bedienen ein a...</td>\n      <td>several men in hard hats are operating a giant...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ein kleines mädchen klettert in ein spielhaus ...</td>\n      <td>a little girl climbing into a wooden playhouse .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ein mann in einem blauen hemd steht auf einer ...</td>\n      <td>a man in a blue shirt is standing on a ladder ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zwei männer stehen am herd und bereiten essen ...</td>\n      <td>two men are at the stove preparing food .</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28995</th>\n      <td>eine frau schreibt hinter einer verschnörkelte...</td>\n      <td>a woman behind a scrolled wall is writing</td>\n    </tr>\n    <tr>\n      <th>28996</th>\n      <td>ein bergsteiger übt an einer kletterwand .</td>\n      <td>a rock climber practices on a rock climbing wa...</td>\n    </tr>\n    <tr>\n      <th>28997</th>\n      <td>zwei bauarbeiter arbeiten auf einer straße vor...</td>\n      <td>two male construction workers are working on a...</td>\n    </tr>\n    <tr>\n      <th>28998</th>\n      <td>ein älterer mann sitzt mit einem jungen mit ei...</td>\n      <td>an elderly man sits outside a storefront accom...</td>\n    </tr>\n    <tr>\n      <th>28999</th>\n      <td>ein mann in shorts und hawaiihemd lehnt sich ü...</td>\n      <td>a man in shorts and a hawaiian shirt leans ove...</td>\n    </tr>\n  </tbody>\n</table>\n<p>29000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def max_len(dataframe, col1, col2):\n    max_length = preprocessed_df[col1].str.len().max()\n    max_text = preprocessed_df.loc[preprocessed_df[col1].str.len() == max_length, col1].iloc[0]\n\n    max_len_eng = len(max_text.split())\n\n    max_length = preprocessed_df[col2].str.len().max()\n    max_text = preprocessed_df.loc[preprocessed_df[col2].str.len() == max_length, col2].iloc[0]\n\n    max_len_de = len(max_text.split())\n\n    return max(max_len_eng, max_len_de)\n\nmax_len = max_len(preprocessed_df, 'english', 'german')\nmax_len","metadata":{"id":"COG0am3mszbz","executionInfo":{"status":"ok","timestamp":1722948156987,"user_tz":-180,"elapsed":363,"user":{"displayName":"","userId":""}},"outputId":"68d4f01e-db05-4e50-9ce2-f1c5572605d3","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-08-06T14:49:08.928884Z","iopub.execute_input":"2024-08-06T14:49:08.929590Z","iopub.status.idle":"2024-08-06T14:49:09.011958Z","shell.execute_reply.started":"2024-08-06T14:49:08.929548Z","shell.execute_reply":"2024-08-06T14:49:09.011044Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"43"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\nseed = 1234\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\n# torch.backends.cudnn.deterministic = True","metadata":{"id":"77CR7HVvszb0","execution":{"iopub.status.busy":"2024-08-06T14:49:14.169351Z","iopub.execute_input":"2024-08-06T14:49:14.170130Z","iopub.status.idle":"2024-08-06T14:49:14.176213Z","shell.execute_reply.started":"2024-08-06T14:49:14.170095Z","shell.execute_reply":"2024-08-06T14:49:14.175271Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.utils.data import Dataset,DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\n\nclass Tokenizer(Dataset):\n\n    def __init__(self, data, max_len=32, get_mask = False, min_freq = 1):\n        super().__init__()\n\n        self.df = data.reset_index(drop=True)\n        self.min_freq = min_freq\n        self.max_len = max_len + 4\n        self.get_mask = get_mask\n        self.src_vocab, self.index2word_src = self.build_vocab(self.df.columns[0])\n        self.trg_vocab, self.index2word_trg = self.build_vocab(self.df.columns[1])\n\n    def get_special_tokens(self):\n        return {'<unk>': 0, '<pad>':1, '<sos>': 2, '<eos>': 3}\n\n    def get_vocab_sizes(self):\n        return len(self.src_vocab), len(self.trg_vocab)\n\n    def build_vocab(self, col):\n        special = list(self.get_special_tokens())\n        freq = {}\n\n        for text in self.df[col]:\n            for word in text.split():\n                if word in freq:\n                    freq[word] +=1\n                else:\n                    freq[word] = 1\n\n        filtered_words = [word for word, count in freq.items() if count >= self.min_freq]\n\n        vocab = special + filtered_words\n        w2idx = {word: idx for idx, word in enumerate(vocab)}\n        idx2w = {idx: word for idx, word in enumerate(vocab)}\n\n        return w2idx, idx2w\n\n    def __getitem__(self, ind):\n\n\n        src_text = self.df[self.df.columns[0]][ind].split()\n        trg_text = self.df[self.df.columns[1]][ind].split()\n\n        special = self.get_special_tokens()\n\n        tokenized_src = [special['<sos>']] + [self.src_vocab.get(word, special['<unk>']) for word in src_text] + [special['<eos>']]\n        tokenized_trg = [special['<sos>']] + [self.trg_vocab.get(word, special['<unk>']) for word in trg_text] + [special['<eos>']]\n\n\n        \"\"\"tokenized_src = [special['<sos>']] + [self.src_vocab[word] for word in src_text if word in self.src_vocab] + [special['<eos>']]\n\n        tokenized_trg = [special['<sos>']] + [ self.trg_vocab[word] for word in trg_text if word in self.trg_vocab] + [special['<eos>']]\"\"\"\n\n        tokenized_src = tokenized_src + [self.src_vocab['<pad>']]*(self.max_len - len(tokenized_src))\n        tokenized_trg = tokenized_trg + [self.trg_vocab['<pad>']]*(self.max_len - len(tokenized_trg))\n\n\n        if self.get_mask:\n            mask_src = [1]*len(tokenized_src) + [0]*(self.max_len - len(tokenized_src))\n            mask_trg = [1]*len(tokenized_trg) + [0]*(self.max_len - len(tokenized_trg))\n\n            return {'src': torch.tensor(tokenized_src),\n                    'trg': torch.tensor(tokenized_trg),\n                    'mask_src': torch.tensor(mask_src),\n                    'mask_trg': torch.tensor(mask_trg)}\n\n\n        return {'src': torch.tensor(tokenized_src),\n                'trg': torch.tensor(tokenized_trg)}\n\n\n    def __len__(self):\n        return len(self.df)\n\nbatch_size = 128\nget_mask = False\n\ntokenized = Tokenizer(preprocessed_df.reset_index(drop=True),\n                      max_len=max_len,\n                      get_mask=get_mask,\n                      min_freq=1)\n\ntrain_data , valid_data = train_test_split(tokenized,\n                                           test_size = 0.2)\n\ntrain_dataloader = DataLoader(train_data,\n                              batch_size=batch_size,\n                              shuffle=True)\n\nvalid_dataloader = DataLoader(valid_data,\n                              batch_size=batch_size,\n                              shuffle=False)","metadata":{"id":"CAPPsdhkszb0","execution":{"iopub.status.busy":"2024-08-06T15:19:50.729034Z","iopub.execute_input":"2024-08-06T15:19:50.730102Z","iopub.status.idle":"2024-08-06T15:19:53.413006Z","shell.execute_reply.started":"2024-08-06T15:19:50.730058Z","shell.execute_reply":"2024-08-06T15:19:53.412220Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import tqdm\nimport random\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers,dropout):\n        super().__init__()\n\n        self.embedding = nn.Embedding(input_dim,\n                                      embedding_dim)\n\n        self.rnn = nn.LSTM(embedding_dim,\n                           hidden_dim,\n                           num_layers=n_layers,\n                           dropout=dropout,\n                           batch_first=True)\n\n        self.dropout = nn.Dropout(dropout)\n\n\n    def forward(self, src):\n        output = self.embedding(src)\n        output = self.dropout(output)\n        outputs, (hidden, cell) = self.rnn(output)\n        return hidden, cell","metadata":{"id":"WJgMU0kuszb1","execution":{"iopub.status.busy":"2024-08-06T15:19:55.878220Z","iopub.execute_input":"2024-08-06T15:19:55.878631Z","iopub.status.idle":"2024-08-06T15:19:55.886248Z","shell.execute_reply.started":"2024-08-06T15:19:55.878596Z","shell.execute_reply":"2024-08-06T15:19:55.885121Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n        super().__init__()\n\n        self.embedding = nn.Embedding(output_dim,\n                                      embedding_dim,\n                                      )\n\n        self.rnn = nn.LSTM(embedding_dim,\n                           hidden_dim,\n                           num_layers=n_layers,\n                           dropout=dropout,\n                           batch_first=True)\n\n        self.dropout = nn.Dropout(dropout)\n\n        self.fc_out = nn.Linear(hidden_dim, output_dim)\n\n\n    def forward(self, trg, hidden, cell):\n        trg = trg.unsqueeze(1)\n        output = self.embedding(trg)\n        output = self.dropout(output)\n\n        output, (hidden, cell) = self.rnn(output, (hidden, cell))\n        prediction = self.fc_out(output.squeeze(1))\n\n        return prediction, hidden, cell","metadata":{"id":"y-3ODGaxszb1","execution":{"iopub.status.busy":"2024-08-06T15:19:58.333439Z","iopub.execute_input":"2024-08-06T15:19:58.333842Z","iopub.status.idle":"2024-08-06T15:19:58.341997Z","shell.execute_reply.started":"2024-08-06T15:19:58.333812Z","shell.execute_reply":"2024-08-06T15:19:58.340979Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device, teacher_forcing_ratio):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.tf = teacher_forcing_ratio\n\n    def forward(self, src, trg):\n\n        trg_len = trg.shape[1]\n        batch_size = trg.shape[0]\n        output_dim = self.decoder.fc_out.out_features\n\n        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n        hidden, cell = self.encoder(src)\n        x = trg[:, 0]\n\n        for t in range(1, trg_len):\n\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            outputs[:, t, :] = output\n\n            teacher_force = torch.rand(1) < self.tf\n            x = trg[:, t] if teacher_force else output.argmax(1)\n\n        return outputs","metadata":{"id":"_D4Av9Erszb1","execution":{"iopub.status.busy":"2024-08-06T15:20:00.516992Z","iopub.execute_input":"2024-08-06T15:20:00.517408Z","iopub.status.idle":"2024-08-06T15:20:00.526105Z","shell.execute_reply.started":"2024-08-06T15:20:00.517377Z","shell.execute_reply":"2024-08-06T15:20:00.525045Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"input_dim, output_dim =  tokenized.get_vocab_sizes()\nencoder_embedding_dim = 256\ndecoder_embedding_dim = 256\nhidden_dim = 512\nn_layers = 2\nteacher_forcing_ratio = 0.5\nencoder_dropout = 0.5\ndecoder_dropout = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nencoder = Encoder(\n    input_dim,\n    encoder_embedding_dim,\n    hidden_dim,\n    n_layers,\n    encoder_dropout,\n).to(device)\n\ndecoder = Decoder(\n    output_dim,\n    decoder_embedding_dim,\n    hidden_dim,\n    n_layers,\n    decoder_dropout,\n).to(device)\n\nmodel = Seq2Seq(encoder, decoder, device, teacher_forcing_ratio)\noptimizer = optim.Adam(model.parameters())\npad_index = tokenized.get_special_tokens()['<pad>']\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"id":"6Onl9rqXszb1","execution":{"iopub.status.busy":"2024-08-06T15:20:03.068525Z","iopub.execute_input":"2024-08-06T15:20:03.068872Z","iopub.status.idle":"2024-08-06T15:20:03.289723Z","shell.execute_reply.started":"2024-08-06T15:20:03.068842Z","shell.execute_reply":"2024-08-06T15:20:03.288745Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def train_fn(\n    model, data_loader, optimizer, criterion, clip, device\n):\n    model.train()\n    epoch_loss = 0\n    for batch in data_loader:\n        src = batch[\"src\"].to(device)\n        trg = batch[\"trg\"].to(device)\n\n\n        optimizer.zero_grad()\n        output = model(src, trg)\n        output_dim = output.shape[-1]\n\n        output = output[:, 1:, :].reshape(-1, output_dim)\n        trg = trg[:, 1:].reshape(-1)\n\n        loss = criterion(output, trg)\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    return epoch_loss / len(data_loader)\n\ndef evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for batch in data_loader:\n\n            src = batch[\"src\"].to(device)\n            trg = batch[\"trg\"].to(device)\n\n            output = model(src, trg)\n            output_dim = output.shape[-1]\n\n            output = output[:, 1:, :].reshape(-1, output_dim)\n            trg = trg[:, 1:].reshape(-1)\n\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n\n    return epoch_loss / len(data_loader)\n\nn_epochs = 10\nclip = 1.0\n\nbest_valid_loss = float(\"inf\")\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_dataloader,\n        optimizer,\n        criterion,\n        clip,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        valid_dataloader,\n        criterion,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"tut1-model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"id":"8vezNQnVszb2","executionInfo":{"status":"ok","timestamp":1722954033608,"user_tz":-180,"elapsed":679731,"user":{"displayName":"","userId":""}},"outputId":"68cd785c-0d1f-4e24-f2d8-49385a026886","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-08-06T15:20:05.537871Z","iopub.execute_input":"2024-08-06T15:20:05.538545Z","iopub.status.idle":"2024-08-06T15:34:03.528898Z","shell.execute_reply.started":"2024-08-06T15:20:05.538505Z","shell.execute_reply":"2024-08-06T15:34:03.527852Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":" 10%|█         | 1/10 [01:23<12:31, 83.48s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   5.220 | Train PPL: 184.842\n\tValid Loss:   4.797 | Valid PPL: 121.090\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [02:47<11:08, 83.62s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.647 | Train PPL: 104.303\n\tValid Loss:   4.514 | Valid PPL:  91.328\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [04:10<09:45, 83.59s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.371 | Train PPL:  79.136\n\tValid Loss:   4.278 | Valid PPL:  72.099\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [05:34<08:21, 83.65s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.130 | Train PPL:  62.185\n\tValid Loss:   4.112 | Valid PPL:  61.093\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [06:58<06:58, 83.69s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.975 | Train PPL:  53.243\n\tValid Loss:   4.002 | Valid PPL:  54.711\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [08:21<05:34, 83.69s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.875 | Train PPL:  48.179\n\tValid Loss:   3.864 | Valid PPL:  47.665\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [09:45<04:11, 83.79s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.729 | Train PPL:  41.649\n\tValid Loss:   3.799 | Valid PPL:  44.670\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [11:09<02:47, 83.84s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.610 | Train PPL:  36.961\n\tValid Loss:   3.706 | Valid PPL:  40.677\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [12:33<01:23, 83.90s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.493 | Train PPL:  32.894\n\tValid Loss:   3.654 | Valid PPL:  38.628\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [13:57<00:00, 83.80s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.404 | Train PPL:  30.094\n\tValid Loss:   3.634 | Valid PPL:  37.849\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"tut1-model.pt\"))\n\ntest_loss = evaluate_fn(model, valid_dataloader, criterion, device)\n\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"id":"29mnmJ49szb2","executionInfo":{"status":"ok","timestamp":1722954077370,"user_tz":-180,"elapsed":7660,"user":{"displayName":"","userId":""}},"outputId":"b1475848-49a9-40b5-ce93-dd58794fc9b1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-08-06T15:34:40.650204Z","iopub.execute_input":"2024-08-06T15:34:40.650621Z","iopub.status.idle":"2024-08-06T15:34:49.824317Z","shell.execute_reply.started":"2024-08-06T15:34:40.650590Z","shell.execute_reply":"2024-08-06T15:34:49.823205Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"| Test Loss: 3.595 | Test PPL:  36.402 |\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(\n    sentence,\n    model,\n    nlp_src,\n    nlp_trg,\n    vocab_src,\n    vocab_trg,\n    lower,\n    sos_token='<sos>',\n    eos_token='<eos>',\n    device=device,\n    max_output_length=20\n):\n    model.eval()\n\n    with torch.no_grad():\n        if isinstance(sentence, str):\n            tokens = [token.text for token in nlp_src.tokenizer(sentence)]\n        else:\n            tokens = [token for token in sentence]\n        if lower:\n            tokens = [token.lower() for token in tokens]\n        tokens = [sos_token] + tokens + [eos_token]\n\n        ids = [vocab_src.get(token, vocab_src[\"<unk>\"]) for token in tokens]\n        tensor = torch.LongTensor(ids).unsqueeze(-1).T.to(device) #.to(device)\n        hidden, cell = model.encoder(tensor)\n        inputs = [vocab_trg[sos_token]]\n        for _ in range(max_output_length):\n            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n            predicted_token = output.argmax(-1).item()\n            inputs.append(predicted_token)\n            if predicted_token == vocab_trg[eos_token]:\n                break\n        \n    return inputs, np.array(list(vocab_trg))[inputs]\n\nnum_s = 0\nsentence = dataset_test[\"german\"][num_s]\nexpected_translation = dataset_test[\"english\"][num_s]\n\nnlp_src = spacy.load(\"de_core_news_sm\")\nnlp_trg = spacy.load(\"en_core_web_sm\")\n\nvocab_src = tokenized.src_vocab\nvocab_trg = tokenized.trg_vocab\nlower = True\n\nprint(sentence)\nprint(expected_translation)\n\n\ntranslate_sentence(\n    sentence,\n    model,\n    nlp_src,\n    nlp_trg,\n    vocab_src,\n    vocab_trg,\n    lower,\n    sos_token='<sos>',\n    eos_token='<eos>',\n    device=device,\n    max_output_length=20,\n)","metadata":{"id":"mRYIbyiOHl_-","executionInfo":{"status":"error","timestamp":1722955453346,"user_tz":-180,"elapsed":3016,"user":{"displayName":"","userId":""}},"outputId":"91a838a9-9f9e-4f73-b106-eb3bf0215387","colab":{"base_uri":"https://localhost:8080/","height":498},"execution":{"iopub.status.busy":"2024-08-06T15:35:33.398543Z","iopub.execute_input":"2024-08-06T15:35:33.398939Z","iopub.status.idle":"2024-08-06T15:35:36.259649Z","shell.execute_reply.started":"2024-08-06T15:35:33.398904Z","shell.execute_reply":"2024-08-06T15:35:36.258726Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\nA man in an orange hat starring at something.\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"([2, 21, 31, 85, 21, 7, 33, 14, 3],\n array(['<sos>', 'a', 'man', 'wearing', 'a', 'white', 'shirt', '.',\n        '<eos>'], dtype='<U16'))"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}