{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-08-06T14:47:10.073131Z","iopub.status.busy":"2024-08-06T14:47:10.072418Z","iopub.status.idle":"2024-08-06T14:47:49.902775Z","shell.execute_reply":"2024-08-06T14:47:49.901644Z","shell.execute_reply.started":"2024-08-06T14:47:10.073100Z"},"executionInfo":{"elapsed":23180,"status":"ok","timestamp":1722948048057,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"3jIQT8iPszbx","outputId":"e3333cb1-d08c-4ee3-8e2e-72719c7e68c2","trusted":true},"outputs":[],"source":["!python3 -m spacy download de_core_news_sm\n","!pip install pandarallel\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"execution":{"iopub.execute_input":"2024-08-06T14:48:15.721638Z","iopub.status.busy":"2024-08-06T14:48:15.721263Z","iopub.status.idle":"2024-08-06T14:48:15.827830Z","shell.execute_reply":"2024-08-06T14:48:15.826651Z","shell.execute_reply.started":"2024-08-06T14:48:15.721609Z"},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1722948051237,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"4CMFOkReszbx","outputId":"40de57aa-b7b6-4b05-a792-745f7ab22c46","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>german</th>\n","      <th>english</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n","      <td>Two young, White males are outside near many b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n","      <td>Several men in hard hats are operating a giant...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n","      <td>A little girl climbing into a wooden playhouse.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ein Mann in einem blauen Hemd steht auf einer ...</td>\n","      <td>A man in a blue shirt is standing on a ladder ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n","      <td>Two men are at the stove preparing food.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>28995</th>\n","      <td>Eine Frau schreibt hinter einer verschnörkelte...</td>\n","      <td>A woman behind a scrolled wall is writing</td>\n","    </tr>\n","    <tr>\n","      <th>28996</th>\n","      <td>Ein Bergsteiger übt an einer Kletterwand.</td>\n","      <td>A rock climber practices on a rock climbing wall.</td>\n","    </tr>\n","    <tr>\n","      <th>28997</th>\n","      <td>Zwei Bauarbeiter arbeiten auf einer Straße vor...</td>\n","      <td>Two male construction workers are working on a...</td>\n","    </tr>\n","    <tr>\n","      <th>28998</th>\n","      <td>Ein älterer Mann sitzt mit einem Jungen mit ei...</td>\n","      <td>An elderly man sits outside a storefront accom...</td>\n","    </tr>\n","    <tr>\n","      <th>28999</th>\n","      <td>Ein Mann in Shorts und Hawaiihemd lehnt sich ü...</td>\n","      <td>A man in shorts and a Hawaiian shirt leans ove...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  german  \\\n","0      Zwei junge weiße Männer sind im Freien in der ...   \n","1      Mehrere Männer mit Schutzhelmen bedienen ein A...   \n","2      Ein kleines Mädchen klettert in ein Spielhaus ...   \n","3      Ein Mann in einem blauen Hemd steht auf einer ...   \n","4      Zwei Männer stehen am Herd und bereiten Essen zu.   \n","...                                                  ...   \n","28995  Eine Frau schreibt hinter einer verschnörkelte...   \n","28996          Ein Bergsteiger übt an einer Kletterwand.   \n","28997  Zwei Bauarbeiter arbeiten auf einer Straße vor...   \n","28998  Ein älterer Mann sitzt mit einem Jungen mit ei...   \n","28999  Ein Mann in Shorts und Hawaiihemd lehnt sich ü...   \n","\n","                                                 english  \n","0      Two young, White males are outside near many b...  \n","1      Several men in hard hats are operating a giant...  \n","2        A little girl climbing into a wooden playhouse.  \n","3      A man in a blue shirt is standing on a ladder ...  \n","4               Two men are at the stove preparing food.  \n","...                                                  ...  \n","28995          A woman behind a scrolled wall is writing  \n","28996  A rock climber practices on a rock climbing wall.  \n","28997  Two male construction workers are working on a...  \n","28998  An elderly man sits outside a storefront accom...  \n","28999  A man in shorts and a Hawaiian shirt leans ove...  \n","\n","[29000 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset = pd.read_csv('/kaggle/input/machine-translation-dataset-de-en/translation_train.csv')\n","dataset_test = pd.read_csv('/kaggle/input/machine-translation-dataset-de-en/translation_test.csv')\n","dataset = dataset[dataset.columns[::-1]]\n","dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-08-06T14:48:18.449763Z","iopub.status.busy":"2024-08-06T14:48:18.449361Z","iopub.status.idle":"2024-08-06T14:49:00.728916Z","shell.execute_reply":"2024-08-06T14:49:00.727860Z","shell.execute_reply.started":"2024-08-06T14:48:18.449733Z"},"executionInfo":{"elapsed":86866,"status":"ok","timestamp":1722948141750,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"NdkdUu9wszby","outputId":"64035ab6-33ca-46c0-86a8-1f0de2cbbc49","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Pandarallel will run on 16 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n","INFO: Pandarallel will run on 16 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n","INFO: Pandarallel will run on 16 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n","INFO: Pandarallel will run on 16 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"]}],"source":["import spacy\n","import nltk\n","\n","def preprocessing(data,\n","                  preprocess_column = 'En',\n","                  n_workers = 32,\n","                  lang_stopwords = None,\n","                  corpus = None,\n","                  lower = False):\n","\n","    import pandarallel\n","    from pandarallel import pandarallel\n","    import re\n","\n","\n","    pandarallel.initialize(progress_bar=False, nb_workers=n_workers)\n","\n","    data = data.copy()\n","    data[preprocess_column] = data[preprocess_column]\n","\n","    pandarallel.initialize(nb_workers=n_workers)\n","\n","\n","    if lower:\n","        data[preprocess_column] = data[preprocess_column].\\\n","                                         parallel_apply(lambda text: text.lower())\n","\n","    if corpus is not None:\n","        nlp = spacy.load(corpus)\n","        data[preprocess_column] = data[preprocess_column].\\\n","                                         parallel_apply(lambda text: \" \".join([token.text for token in nlp.tokenizer(text)]))\n","    if lang_stopwords is not None:\n","        sw = nltk.corpus.stopwords.words(lang_stopwords)\n","        data[preprocess_column] = data[preprocess_column].\\\n","                                         parallel_apply(lambda text: \" \".join([word for word in text.split() if word not in sw]))\n","\n","    return data\n","\n","\n","en_corpus = 'en_core_web_sm'\n","de_corpus = 'de_core_news_sm'\n","\n","preprocessed_df = preprocessing(dataset,\n","                                preprocess_column = 'english',\n","                                corpus = en_corpus,\n","                                lower=True,\n","                                n_workers = 16)\n","\n","preprocessed_df = preprocessing(preprocessed_df,\n","                                preprocess_column = 'german',\n","                                corpus = de_corpus,\n","                                lower=True,\n","                                n_workers = 16)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"execution":{"iopub.execute_input":"2024-08-06T14:49:05.721475Z","iopub.status.busy":"2024-08-06T14:49:05.720308Z","iopub.status.idle":"2024-08-06T14:49:05.734814Z","shell.execute_reply":"2024-08-06T14:49:05.733572Z","shell.execute_reply.started":"2024-08-06T14:49:05.721441Z"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1722948148366,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"cL-HuK0Oszbz","outputId":"1e1f1a16-e19d-489b-c151-c59d3da8547c","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>german</th>\n","      <th>english</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>zwei junge weiße männer sind im freien in der ...</td>\n","      <td>two young , white males are outside near many ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mehrere männer mit schutzhelmen bedienen ein a...</td>\n","      <td>several men in hard hats are operating a giant...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ein kleines mädchen klettert in ein spielhaus ...</td>\n","      <td>a little girl climbing into a wooden playhouse .</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ein mann in einem blauen hemd steht auf einer ...</td>\n","      <td>a man in a blue shirt is standing on a ladder ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>zwei männer stehen am herd und bereiten essen ...</td>\n","      <td>two men are at the stove preparing food .</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>28995</th>\n","      <td>eine frau schreibt hinter einer verschnörkelte...</td>\n","      <td>a woman behind a scrolled wall is writing</td>\n","    </tr>\n","    <tr>\n","      <th>28996</th>\n","      <td>ein bergsteiger übt an einer kletterwand .</td>\n","      <td>a rock climber practices on a rock climbing wa...</td>\n","    </tr>\n","    <tr>\n","      <th>28997</th>\n","      <td>zwei bauarbeiter arbeiten auf einer straße vor...</td>\n","      <td>two male construction workers are working on a...</td>\n","    </tr>\n","    <tr>\n","      <th>28998</th>\n","      <td>ein älterer mann sitzt mit einem jungen mit ei...</td>\n","      <td>an elderly man sits outside a storefront accom...</td>\n","    </tr>\n","    <tr>\n","      <th>28999</th>\n","      <td>ein mann in shorts und hawaiihemd lehnt sich ü...</td>\n","      <td>a man in shorts and a hawaiian shirt leans ove...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  german  \\\n","0      zwei junge weiße männer sind im freien in der ...   \n","1      mehrere männer mit schutzhelmen bedienen ein a...   \n","2      ein kleines mädchen klettert in ein spielhaus ...   \n","3      ein mann in einem blauen hemd steht auf einer ...   \n","4      zwei männer stehen am herd und bereiten essen ...   \n","...                                                  ...   \n","28995  eine frau schreibt hinter einer verschnörkelte...   \n","28996         ein bergsteiger übt an einer kletterwand .   \n","28997  zwei bauarbeiter arbeiten auf einer straße vor...   \n","28998  ein älterer mann sitzt mit einem jungen mit ei...   \n","28999  ein mann in shorts und hawaiihemd lehnt sich ü...   \n","\n","                                                 english  \n","0      two young , white males are outside near many ...  \n","1      several men in hard hats are operating a giant...  \n","2       a little girl climbing into a wooden playhouse .  \n","3      a man in a blue shirt is standing on a ladder ...  \n","4              two men are at the stove preparing food .  \n","...                                                  ...  \n","28995          a woman behind a scrolled wall is writing  \n","28996  a rock climber practices on a rock climbing wa...  \n","28997  two male construction workers are working on a...  \n","28998  an elderly man sits outside a storefront accom...  \n","28999  a man in shorts and a hawaiian shirt leans ove...  \n","\n","[29000 rows x 2 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["preprocessed_df"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-08-06T14:49:08.929590Z","iopub.status.busy":"2024-08-06T14:49:08.928884Z","iopub.status.idle":"2024-08-06T14:49:09.011958Z","shell.execute_reply":"2024-08-06T14:49:09.011044Z","shell.execute_reply.started":"2024-08-06T14:49:08.929548Z"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1722948156987,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"COG0am3mszbz","outputId":"68d4f01e-db05-4e50-9ce2-f1c5572605d3","trusted":true},"outputs":[{"data":{"text/plain":["43"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["def max_len(dataframe, col1, col2):\n","    max_length = preprocessed_df[col1].str.len().max()\n","    max_text = preprocessed_df.loc[preprocessed_df[col1].str.len() == max_length, col1].iloc[0]\n","\n","    max_len_eng = len(max_text.split())\n","\n","    max_length = preprocessed_df[col2].str.len().max()\n","    max_text = preprocessed_df.loc[preprocessed_df[col2].str.len() == max_length, col2].iloc[0]\n","\n","    max_len_de = len(max_text.split())\n","\n","    return max(max_len_eng, max_len_de)\n","\n","max_len = max_len(preprocessed_df, 'english', 'german')\n","max_len"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T14:49:14.170130Z","iopub.status.busy":"2024-08-06T14:49:14.169351Z","iopub.status.idle":"2024-08-06T14:49:14.176213Z","shell.execute_reply":"2024-08-06T14:49:14.175271Z","shell.execute_reply.started":"2024-08-06T14:49:14.170095Z"},"id":"77CR7HVvszb0","trusted":true},"outputs":[],"source":["import random\n","\n","seed = 1234\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","# torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T15:19:50.730102Z","iopub.status.busy":"2024-08-06T15:19:50.729034Z","iopub.status.idle":"2024-08-06T15:19:53.413006Z","shell.execute_reply":"2024-08-06T15:19:53.412220Z","shell.execute_reply.started":"2024-08-06T15:19:50.730058Z"},"id":"CAPPsdhkszb0","trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset,DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","from torch.utils.data import Dataset,DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","class Tokenizer(Dataset):\n","\n","    def __init__(self, data, max_len=32, get_mask = False, min_freq = 1):\n","        super().__init__()\n","\n","        self.df = data.reset_index(drop=True)\n","        self.min_freq = min_freq\n","        self.max_len = max_len + 4\n","        self.get_mask = get_mask\n","        self.src_vocab, self.index2word_src = self.build_vocab(self.df.columns[0])\n","        self.trg_vocab, self.index2word_trg = self.build_vocab(self.df.columns[1])\n","\n","    def get_special_tokens(self):\n","        return {'<unk>': 0, '<pad>':1, '<sos>': 2, '<eos>': 3}\n","\n","    def get_vocab_sizes(self):\n","        return len(self.src_vocab), len(self.trg_vocab)\n","\n","    def build_vocab(self, col):\n","        special = list(self.get_special_tokens())\n","        freq = {}\n","\n","        for text in self.df[col]:\n","            for word in text.split():\n","                if word in freq:\n","                    freq[word] +=1\n","                else:\n","                    freq[word] = 1\n","\n","        filtered_words = [word for word, count in freq.items() if count >= self.min_freq]\n","\n","        vocab = special + filtered_words\n","        w2idx = {word: idx for idx, word in enumerate(vocab)}\n","        idx2w = {idx: word for idx, word in enumerate(vocab)}\n","\n","        return w2idx, idx2w\n","\n","    def __getitem__(self, ind):\n","\n","\n","        src_text = self.df[self.df.columns[0]][ind].split()\n","        trg_text = self.df[self.df.columns[1]][ind].split()\n","\n","        special = self.get_special_tokens()\n","\n","        tokenized_src = [special['<sos>']] + [self.src_vocab.get(word, special['<unk>']) for word in src_text] + [special['<eos>']]\n","        tokenized_trg = [special['<sos>']] + [self.trg_vocab.get(word, special['<unk>']) for word in trg_text] + [special['<eos>']]\n","\n","        tokenized_src = tokenized_src + [self.src_vocab['<pad>']]*(self.max_len - len(tokenized_src))\n","        tokenized_trg = tokenized_trg + [self.trg_vocab['<pad>']]*(self.max_len - len(tokenized_trg))\n","\n","\n","        if self.get_mask:\n","            mask_src = [1]*len(tokenized_src) + [0]*(self.max_len - len(tokenized_src))\n","            mask_trg = [1]*len(tokenized_trg) + [0]*(self.max_len - len(tokenized_trg))\n","\n","            return {'src': torch.tensor(tokenized_src),\n","                    'trg': torch.tensor(tokenized_trg),\n","                    'mask_src': torch.tensor(mask_src),\n","                    'mask_trg': torch.tensor(mask_trg)}\n","\n","\n","        return {'src': torch.tensor(tokenized_src),\n","                'trg': torch.tensor(tokenized_trg)}\n","\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","batch_size = 128\n","get_mask = False\n","\n","tokenized = Tokenizer(preprocessed_df.reset_index(drop=True),\n","                      max_len=max_len,\n","                      get_mask=get_mask,\n","                      min_freq=1)\n","\n","train_data , valid_data = train_test_split(tokenized,\n","                                           test_size = 0.2)\n","\n","train_dataloader = DataLoader(train_data,\n","                              batch_size=batch_size,\n","                              shuffle=True)\n","\n","valid_dataloader = DataLoader(valid_data,\n","                              batch_size=batch_size,\n","                              shuffle=False)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T15:19:55.878631Z","iopub.status.busy":"2024-08-06T15:19:55.878220Z","iopub.status.idle":"2024-08-06T15:19:55.886248Z","shell.execute_reply":"2024-08-06T15:19:55.885121Z","shell.execute_reply.started":"2024-08-06T15:19:55.878596Z"},"id":"WJgMU0kuszb1","trusted":true},"outputs":[],"source":["import tqdm\n","import random\n","import torch.nn as nn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers,dropout):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(input_dim,\n","                                      embedding_dim)\n","\n","        self.rnn = nn.LSTM(embedding_dim,\n","                           hidden_dim,\n","                           num_layers=n_layers,\n","                           dropout=dropout,\n","                           batch_first=True)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def forward(self, src):\n","        output = self.embedding(src)\n","        output = self.dropout(output)\n","        outputs, (hidden, cell) = self.rnn(output)\n","        return hidden, cell"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T15:19:58.333842Z","iopub.status.busy":"2024-08-06T15:19:58.333439Z","iopub.status.idle":"2024-08-06T15:19:58.341997Z","shell.execute_reply":"2024-08-06T15:19:58.340979Z","shell.execute_reply.started":"2024-08-06T15:19:58.333812Z"},"id":"y-3ODGaxszb1","trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(output_dim,\n","                                      embedding_dim,\n","                                      )\n","\n","        self.rnn = nn.LSTM(embedding_dim,\n","                           hidden_dim,\n","                           num_layers=n_layers,\n","                           dropout=dropout,\n","                           batch_first=True)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","\n","\n","    def forward(self, trg, hidden, cell):\n","        trg = trg.unsqueeze(1)\n","        output = self.embedding(trg)\n","        output = self.dropout(output)\n","\n","        output, (hidden, cell) = self.rnn(output, (hidden, cell))\n","        prediction = self.fc_out(output.squeeze(1))\n","\n","        return prediction, hidden, cell"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T15:20:00.517408Z","iopub.status.busy":"2024-08-06T15:20:00.516992Z","iopub.status.idle":"2024-08-06T15:20:00.526105Z","shell.execute_reply":"2024-08-06T15:20:00.525045Z","shell.execute_reply.started":"2024-08-06T15:20:00.517377Z"},"id":"_D4Av9Erszb1","trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device, teacher_forcing_ratio):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        self.tf = teacher_forcing_ratio\n","\n","    def forward(self, src, trg):\n","\n","        trg_len = trg.shape[1]\n","        batch_size = trg.shape[0]\n","        output_dim = self.decoder.fc_out.out_features\n","\n","        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n","        hidden, cell = self.encoder(src)\n","        x = trg[:, 0]\n","\n","        for t in range(1, trg_len):\n","\n","            output, hidden, cell = self.decoder(x, hidden, cell)\n","            outputs[:, t, :] = output\n","\n","            teacher_force = torch.rand(1) < self.tf\n","            x = trg[:, t] if teacher_force else output.argmax(1)\n","\n","        return outputs"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T15:20:03.068872Z","iopub.status.busy":"2024-08-06T15:20:03.068525Z","iopub.status.idle":"2024-08-06T15:20:03.289723Z","shell.execute_reply":"2024-08-06T15:20:03.288745Z","shell.execute_reply.started":"2024-08-06T15:20:03.068842Z"},"id":"6Onl9rqXszb1","trusted":true},"outputs":[],"source":["input_dim, output_dim =  tokenized.get_vocab_sizes()\n","encoder_embedding_dim = 256\n","decoder_embedding_dim = 256\n","hidden_dim = 512\n","n_layers = 2\n","teacher_forcing_ratio = 0.5\n","encoder_dropout = 0.5\n","decoder_dropout = 0.5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","encoder = Encoder(\n","    input_dim,\n","    encoder_embedding_dim,\n","    hidden_dim,\n","    n_layers,\n","    encoder_dropout,\n",").to(device)\n","\n","decoder = Decoder(\n","    output_dim,\n","    decoder_embedding_dim,\n","    hidden_dim,\n","    n_layers,\n","    decoder_dropout,\n",").to(device)\n","\n","model = Seq2Seq(encoder, decoder, device, teacher_forcing_ratio)\n","optimizer = optim.Adam(model.parameters())\n","pad_index = tokenized.get_special_tokens()['<pad>']\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-08-06T15:20:05.538545Z","iopub.status.busy":"2024-08-06T15:20:05.537871Z","iopub.status.idle":"2024-08-06T15:34:03.528898Z","shell.execute_reply":"2024-08-06T15:34:03.527852Z","shell.execute_reply.started":"2024-08-06T15:20:05.538505Z"},"executionInfo":{"elapsed":679731,"status":"ok","timestamp":1722954033608,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"8vezNQnVszb2","outputId":"68cd785c-0d1f-4e24-f2d8-49385a026886","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":[" 10%|█         | 1/10 [01:23<12:31, 83.48s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   5.220 | Train PPL: 184.842\n","\tValid Loss:   4.797 | Valid PPL: 121.090\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 2/10 [02:47<11:08, 83.62s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   4.647 | Train PPL: 104.303\n","\tValid Loss:   4.514 | Valid PPL:  91.328\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 3/10 [04:10<09:45, 83.59s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   4.371 | Train PPL:  79.136\n","\tValid Loss:   4.278 | Valid PPL:  72.099\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 4/10 [05:34<08:21, 83.65s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   4.130 | Train PPL:  62.185\n","\tValid Loss:   4.112 | Valid PPL:  61.093\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 5/10 [06:58<06:58, 83.69s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   3.975 | Train PPL:  53.243\n","\tValid Loss:   4.002 | Valid PPL:  54.711\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 6/10 [08:21<05:34, 83.69s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   3.875 | Train PPL:  48.179\n","\tValid Loss:   3.864 | Valid PPL:  47.665\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 7/10 [09:45<04:11, 83.79s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   3.729 | Train PPL:  41.649\n","\tValid Loss:   3.799 | Valid PPL:  44.670\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 8/10 [11:09<02:47, 83.84s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   3.610 | Train PPL:  36.961\n","\tValid Loss:   3.706 | Valid PPL:  40.677\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 9/10 [12:33<01:23, 83.90s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   3.493 | Train PPL:  32.894\n","\tValid Loss:   3.654 | Valid PPL:  38.628\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [13:57<00:00, 83.80s/it]"]},{"name":"stdout","output_type":"stream","text":["\tTrain Loss:   3.404 | Train PPL:  30.094\n","\tValid Loss:   3.634 | Valid PPL:  37.849\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def train_fn(\n","    model, data_loader, optimizer, criterion, clip, device\n","):\n","    model.train()\n","    epoch_loss = 0\n","    for batch in data_loader:\n","        src = batch[\"src\"].to(device)\n","        trg = batch[\"trg\"].to(device)\n","\n","\n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        output_dim = output.shape[-1]\n","\n","        output = output[:, 1:, :].reshape(-1, output_dim)\n","        trg = trg[:, 1:].reshape(-1)\n","\n","        loss = criterion(output, trg)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(data_loader)\n","\n","def evaluate_fn(model, data_loader, criterion, device):\n","    model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","        for batch in data_loader:\n","\n","            src = batch[\"src\"].to(device)\n","            trg = batch[\"trg\"].to(device)\n","\n","            output = model(src, trg)\n","            output_dim = output.shape[-1]\n","\n","            output = output[:, 1:, :].reshape(-1, output_dim)\n","            trg = trg[:, 1:].reshape(-1)\n","\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(data_loader)\n","\n","n_epochs = 10\n","clip = 1.0\n","\n","best_valid_loss = float(\"inf\")\n","for epoch in tqdm.tqdm(range(n_epochs)):\n","    train_loss = train_fn(\n","        model,\n","        train_dataloader,\n","        optimizer,\n","        criterion,\n","        clip,\n","        device,\n","    )\n","    valid_loss = evaluate_fn(\n","        model,\n","        valid_dataloader,\n","        criterion,\n","        device,\n","    )\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), \"tut1-model.pt\")\n","    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n","    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-08-06T15:34:40.650621Z","iopub.status.busy":"2024-08-06T15:34:40.650204Z","iopub.status.idle":"2024-08-06T15:34:49.824317Z","shell.execute_reply":"2024-08-06T15:34:49.823205Z","shell.execute_reply.started":"2024-08-06T15:34:40.650590Z"},"executionInfo":{"elapsed":7660,"status":"ok","timestamp":1722954077370,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"29mnmJ49szb2","outputId":"b1475848-49a9-40b5-ce93-dd58794fc9b1","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["| Test Loss: 3.595 | Test PPL:  36.402 |\n"]}],"source":["model.load_state_dict(torch.load(\"tut1-model.pt\"))\n","\n","test_loss = evaluate_fn(model, valid_dataloader, criterion, device)\n","\n","print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498},"execution":{"iopub.execute_input":"2024-08-06T15:35:33.398939Z","iopub.status.busy":"2024-08-06T15:35:33.398543Z","iopub.status.idle":"2024-08-06T15:35:36.259649Z","shell.execute_reply":"2024-08-06T15:35:36.258726Z","shell.execute_reply.started":"2024-08-06T15:35:33.398904Z"},"executionInfo":{"elapsed":3016,"status":"error","timestamp":1722955453346,"user":{"displayName":"","userId":""},"user_tz":-180},"id":"mRYIbyiOHl_-","outputId":"91a838a9-9f9e-4f73-b106-eb3bf0215387","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n","A man in an orange hat starring at something.\n"]},{"data":{"text/plain":["([2, 21, 31, 85, 21, 7, 33, 14, 3],\n"," array(['<sos>', 'a', 'man', 'wearing', 'a', 'white', 'shirt', '.',\n","        '<eos>'], dtype='<U16'))"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["def translate_sentence(\n","    sentence,\n","    model,\n","    nlp_src,\n","    nlp_trg,\n","    vocab_src,\n","    vocab_trg,\n","    lower,\n","    sos_token='<sos>',\n","    eos_token='<eos>',\n","    device=device,\n","    max_output_length=20\n","):\n","    model.eval()\n","\n","    with torch.no_grad():\n","        if isinstance(sentence, str):\n","            tokens = [token.text for token in nlp_src.tokenizer(sentence)]\n","        else:\n","            tokens = [token for token in sentence]\n","        if lower:\n","            tokens = [token.lower() for token in tokens]\n","        tokens = [sos_token] + tokens + [eos_token]\n","\n","        ids = [vocab_src.get(token, vocab_src[\"<unk>\"]) for token in tokens]\n","        tensor = torch.LongTensor(ids).unsqueeze(-1).T.to(device) #.to(device)\n","        hidden, cell = model.encoder(tensor)\n","        inputs = [vocab_trg[sos_token]]\n","        for _ in range(max_output_length):\n","            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n","            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n","            predicted_token = output.argmax(-1).item()\n","            inputs.append(predicted_token)\n","            if predicted_token == vocab_trg[eos_token]:\n","                break\n","        \n","    return inputs, np.array(list(vocab_trg))[inputs]\n","\n","num_s = 0\n","sentence = dataset_test[\"german\"][num_s]\n","expected_translation = dataset_test[\"english\"][num_s]\n","\n","nlp_src = spacy.load(\"de_core_news_sm\")\n","nlp_trg = spacy.load(\"en_core_web_sm\")\n","\n","vocab_src = tokenized.src_vocab\n","vocab_trg = tokenized.trg_vocab\n","lower = True\n","\n","print(sentence)\n","print(expected_translation)\n","\n","\n","translate_sentence(\n","    sentence,\n","    model,\n","    nlp_src,\n","    nlp_trg,\n","    vocab_src,\n","    vocab_trg,\n","    lower,\n","    sos_token='<sos>',\n","    eos_token='<eos>',\n","    device=device,\n","    max_output_length=20,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/seq2seq-f256f7cc-0e31-41eb-b554-8150c37bf037.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240806/auto/storage/goog4_request&X-Goog-Date=20240806T123900Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=3f6ec6c27384e87bff2d3c33e53eb638b6dd7e37079f835378ef5c635a8172c410d20bdf212dd5f9a4e957845317a03bc20ab26c9e5c70d7cd50c88804ce1133299e4b40fbe7eb3e9889d31cebc25c155e21dfef95d1eb46db901f30ec0adca4d94cd7e56e5a2e7e619212e148f7be8842bacbe167b2ffcf2c60c3e1235d0cabf744132426386a5f73bff9a31c5010dc53beffa9e3ecd1005b8975aca69b6a4244f1137fd8374904b5472acb28c381590e71fad442bd7a9718fb7ef8b3ae99fd693e9eb4e94ace544b7bdb10bc83ff43a0158875da82241b63685170915aae699ac2af3530606b020ccf6719355d4b49155751586c29623a40f2c4a5b62c0d0a","timestamp":1722955542958}]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":592212,"sourceId":1067156,"sourceType":"datasetVersion"},{"datasetId":1416132,"sourceId":2345761,"sourceType":"datasetVersion"},{"datasetId":1800581,"sourceId":2936819,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
